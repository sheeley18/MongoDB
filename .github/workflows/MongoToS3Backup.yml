name: MongoDB Backup to S3

on:
  # Manual trigger
  workflow_dispatch:
  
  # Automatic daily backup at midnight UTC
  schedule:
    - cron: '0 0 * * *'
    
  # Alternative: Midnight Eastern Time (4 AM UTC in summer, 5 AM UTC in winter)
  # schedule:
  #   - cron: '0 4 * * *'  # Use this for EST/EDT midnight

jobs:
  backup-mongodb:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
      
    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v3
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1
        
    - name: Get Infrastructure Details
      run: |
        echo "Getting infrastructure details from AWS..."
        
        # Get EC2 IP directly from AWS
        EC2_IP=$(aws ec2 describe-instances \
          --filters "Name=tag:Name,Values=TASKY_MONGODB" "Name=instance-state-name,Values=running" \
          --query 'Reservations[0].Instances[0].PublicIpAddress' \
          --output text)
        
        # Get S3 bucket directly from AWS  
        S3_BUCKET=$(aws s3api list-buckets \
          --query 'Buckets[?starts_with(Name, `tasky-mongo-bucket`)].Name' \
          --output text)
        
        # Validate we got values
        if [ "$EC2_IP" = "None" ] || [ -z "$EC2_IP" ]; then
          echo "ERROR: Could not find running EC2 instance with tag Name=TASKY_MONGODB"
          aws ec2 describe-instances --filters "Name=tag:Name,Values=TASKY_MONGODB" --query 'Reservations[].Instances[].[InstanceId,State.Name,Tags[?Key==`Name`].Value|[0]]' --output table
          exit 1
        fi
        
        if [ -z "$S3_BUCKET" ]; then
          echo "ERROR: Could not find S3 bucket starting with 'tasky-mongo-bucket'"
          aws s3api list-buckets --query 'Buckets[].Name' --output table
          exit 1
        fi
        
        echo "EC2 IP: $EC2_IP"
        echo "S3 Bucket: $S3_BUCKET"
        
        echo "EC2_IP=$EC2_IP" >> $GITHUB_ENV
        echo "S3_BUCKET=$S3_BUCKET" >> $GITHUB_ENV
        
    - name: Install MongoDB Tools
      run: |
        curl -fsSL https://pgp.mongodb.com/server-7.0.asc | sudo apt-key add -
        echo "deb https://repo.mongodb.org/apt/ubuntu jammy/mongodb-org/7.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-7.0.list
        sudo apt-get update
        sudo apt-get install -y mongodb-org-tools
        
    - name: Create MongoDB Backup via SSH
      run: |
        echo "Setting up secure SSH connection to EC2..."
        
        # Create SSH directory and key file
        mkdir -p ~/.ssh
        echo "${{ secrets.EC2_SSH_PRIVATE_KEY }}" > ~/.ssh/ec2_key.pem
        chmod 600 ~/.ssh/ec2_key.pem
        
        # Add EC2 host to known hosts to avoid interactive prompt
        ssh-keyscan -H ${{ env.EC2_IP }} >> ~/.ssh/known_hosts 2>/dev/null
        
        # Test SSH connection
        echo "Testing SSH connection..."
        ssh -i ~/.ssh/ec2_key.pem -o ConnectTimeout=10 ubuntu@${{ env.EC2_IP }} "echo 'SSH connection successful'"
        
        # Get timestamp for backup
        TIMESTAMP=$(date +%Y%m%d-%H%M%S)
        echo "TIMESTAMP=$TIMESTAMP" >> $GITHUB_ENV
        
        # Run backup commands on EC2 instance
        echo "Creating MongoDB backup on EC2 instance..."
        ssh -i ~/.ssh/ec2_key.pem ubuntu@${{ env.EC2_IP }} << EOF
          set -e  # Exit on any error
          
          echo "Starting backup process on EC2..."
          TIMESTAMP=$TIMESTAMP
          BACKUP_DIR="/tmp/mongodb-backup-\$TIMESTAMP"
          
          # Create MongoDB dump locally (no network restrictions)
          echo "Creating MongoDB dump..."
          mongodump --host localhost:27017 --db tasky --out "\$BACKUP_DIR"
          
          # Verify dump was created
          if [ ! -d "\$BACKUP_DIR/tasky" ]; then
            echo "ERROR: MongoDB dump failed"
            exit 1
          fi
          
          echo "MongoDB dump created successfully"
          ls -la "\$BACKUP_DIR/tasky/"
          
          # Compress the dump
          echo "Compressing backup..."
          cd /tmp
          tar -czf "tasky-backup-\$TIMESTAMP.tar.gz" "mongodb-backup-\$TIMESTAMP/"
          
          # Get S3 bucket name (EC2 has IAM permissions)
          S3_BUCKET=\$(aws s3 ls | grep tasky-mongo-bucket | awk '{print \$3}')
          echo "Using S3 bucket: \$S3_BUCKET"
          
          # Upload to S3 (EC2 has proper IAM permissions)
          echo "Uploading compressed backup to S3..."
          aws s3 cp "tasky-backup-\$TIMESTAMP.tar.gz" "s3://\$S3_BUCKET/mongodb-backups/"
          
          echo "Uploading raw dump to S3..."
          aws s3 cp "mongodb-backup-\$TIMESTAMP" "s3://\$S3_BUCKET/mongodb-backups/dump-\$TIMESTAMP" --recursive
          
          # Verify uploads
          echo "Verifying S3 uploads..."
          aws s3 ls "s3://\$S3_BUCKET/mongodb-backups/" | grep "\$TIMESTAMP"
          
          # Clean up local files
          echo "Cleaning up local backup files..."
          rm -rf "mongodb-backup-\$TIMESTAMP" "tasky-backup-\$TIMESTAMP.tar.gz"
          
          echo "Backup completed successfully!"
          echo "Compressed backup: s3://\$S3_BUCKET/mongodb-backups/tasky-backup-\$TIMESTAMP.tar.gz"
          echo "Raw dump: s3://\$S3_BUCKET/mongodb-backups/dump-\$TIMESTAMP/"
        EOF
        
        echo "Remote backup process completed successfully!"
        
    - name: Verify Backup Completion
      run: |
        echo "Verifying backup was uploaded to S3..."
        aws s3 ls s3://${{ env.S3_BUCKET }}/mongodb-backups/ --human-readable
        
        # Check for today's backup
        BACKUP_COUNT=$(aws s3 ls s3://${{ env.S3_BUCKET }}/mongodb-backups/ | grep $(date +%Y%m%d) | wc -l)
        if [ $BACKUP_COUNT -gt 0 ]; then
          echo "Backup completed successfully!"
          echo "Found $BACKUP_COUNT backup files for today in S3"
        else
          echo "No backup files found for today"
          exit 1
        fi
